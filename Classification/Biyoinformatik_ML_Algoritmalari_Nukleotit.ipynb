{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Biyoinformatik makine öğrenmesi için:\n",
        "İlk adım veri kümesi oluşturmak olacak. Örnek bir veri kümesi olarak, DNA, RNA veya protein dizilimlerine dair veriler kullanılabilir. Burada **sınıflandırma işlemi** yapacağımızı düşünürsek, örneğin belirli genetik özelliklere göre hastalık riski taşıyan ve taşımayan bireylerin sınıflandırılması güzel bir proje konusu olabilir.\n",
        "\n",
        "1. **Veri Kümesi Oluşturma:**\n",
        "   - Örnek veri olarak insan genomu dizilimlerinden alınan verileri kullanabiliriz. Ya da, literatürde yer alan hazır veri kümelerini alıp işleyebiliriz. Kaggle gibi platformlardan biyoinformatik veri setleri bulmak mümkün. Örnek olarak, **Breast Cancer Gene Expression** veya **Human Gene Mutation Data** gibi veri kümelerini kullanabiliriz.\n",
        "   - Eğer kendimiz bir veri oluşturacaksak, örneğin her satırda bireylere ait genetik bilgi ve bir sınıf (hastalıklı/hastalıksız) yer alabilir.\n",
        "\n",
        "2. **Veri Ön İşleme:**\n",
        "   - Veride eksik değerlerin doldurulması, gereksiz sütunların kaldırılması gibi işlemler yapılmalıdır.\n",
        "   - Genetik veriler üzerinde normalizasyon gerekebilir, çünkü gen dizilimlerinin boyutları oldukça büyük olabilir.\n",
        "\n",
        "3. **Özellik Seçimi (Feature Selection):**\n",
        "   - Genetik veride çok fazla özellik bulunabileceği için en anlamlı özelliklerin seçilmesi önemlidir. Örneğin, belirli mutasyonların veya gen ifadelerinin hastalıklarla ilişkili olup olmadığını bulmak için **PCA (Principal Component Analysis)** veya **mutual information** gibi teknikler kullanılabilir.\n",
        "\n",
        "4. **Model Oluşturma:**\n",
        "   - Sınıflandırma işlemi için **Naive Bayes, Lojistik Regresyon, Destek Vektör Makineleri (SVM)** gibi modelleri kullanabiliriz.\n",
        "   - Eğer isterseniz, daha gelişmiş modellerle (örneğin CNN) genetik dizilimlerdeki örüntüleri de sınıflandırabilirsiniz.\n",
        "\n",
        "5. **Model Eğitimi ve Değerlendirme:**\n",
        "   - Eğitim ve test seti olarak veriyi ayırırız. Daha sonra modeli eğitip, **accuracy, precision, recall** gibi metriklerle değerlendirebiliriz.\n",
        "\n",
        "Örnek Veri Kümesi:\n",
        "\n",
        "| ID  | Genetik Veri (G1, G2, G3...) | Sınıf (Hastalık Riski: 0 veya 1) |\n",
        "|-----|------------------------------|---------------------------------|\n",
        "| 1   | GATTACA...                    | 0                               |\n",
        "| 2   | CGTACGA...                    | 1                               |\n",
        "\n"
      ],
      "metadata": {
        "id": "bnH6IjwK2dBf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "eVkI3U5219Sy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5f137129-ed13-46d8-d9b2-9aa8c87fe068"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'genetik_veri.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Veri kümesi için örnek genetik veriler ve sınıflar oluşturuluyor\n",
        "def random_genetic_data():\n",
        "    \"\"\" Rastgele genetik veri üretir. \"\"\"\n",
        "    return ''.join(random.choices(['A', 'T', 'G', 'C'], k=10))\n",
        "\n",
        "# 100 örnek veri oluşturuyoruz\n",
        "data = {\n",
        "    'ID': [i for i in range(1, 101)],\n",
        "    'Genetic_Data': [random_genetic_data() for _ in range(100)],\n",
        "    'Class': [random.choice([0, 1]) for _ in range(100)]  # 0: Hastalıksız, 1: Hastalık Riski\n",
        "}\n",
        "\n",
        "# Veri çerçevesine dönüştürme\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Dosya olarak kaydetme\n",
        "file_path = 'genetik_veri.csv'\n",
        "df.to_csv(file_path, index=False)\n",
        "\n",
        "file_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CountVectorizer:** Genetik dizileri (ATGC gibi) sayısal vektörlere dönüştürmek için kullanılır. Burada, iki nükleotidden oluşan \"bigram\"lar oluşturduk. Bu sayısal veriler, makine öğrenmesi algoritmalarıyla çalışmak için kullanılır.\n",
        "\n",
        "**Logistic Regression:** Basit bir sınıflandırma algoritması. Hastalık riski olan/olmayan bireyleri tahmin eder.\n",
        "\n",
        "**Model Performansı:** Modelin doğruluk oranını (accuracy) ve sınıflandırma raporunu (classification_report) yazdırır. Bu raporda precision, recall ve F1-score gibi performans ölçütleri bulunur."
      ],
      "metadata": {
        "id": "VrpvJbvN35Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "file_path = 'genetik_veri.csv'\n",
        "\n",
        "# 1. Veri Kümesini Yükleme\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 2. Veri Ön İşleme\n",
        "# Genetik veri dizilimlerini sayısal verilere dönüştürmek için CountVectorizer kullanacağız\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 1))  # Karakter bazlı n-gram\n",
        "X = vectorizer.fit_transform(df['Genetic_Data'])  # Genetik veriyi dönüştürüyoruz\n",
        "y = df['Class']  # Sınıf etiketleri\n",
        "\n",
        "# 3. Veriyi Eğitim ve Test Setlerine Ayırma\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Seyrek veriyi yoğun formata dönüştürme (Naive Bayes için)\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "# 4. Farklı Makine Öğrenmesi Modellerini Eğitme ve Performans Analizi\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Support Vector Machine': SVC(),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "# Sonuçları saklamak için bir liste\n",
        "results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    # Modeli eğitme\n",
        "    if model_name == 'Naive Bayes':\n",
        "        model.fit(X_train_dense, y_train)  # Yoğun veri kullan\n",
        "    else:\n",
        "        model.fit(X_train, y_train)  # Seyrek veri kullan\n",
        "\n",
        "    # Test setinde tahmin yapma\n",
        "    y_pred = model.predict(X_test_dense if model_name == 'Naive Bayes' else X_test)\n",
        "\n",
        "    # Doğruluk hesaplama\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Sonuçları listeye ekleme\n",
        "    results.append({'Model': model_name, 'Accuracy': accuracy})\n",
        "\n",
        "    # Model performansını yazdırma\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Sonuçları DataFrame'e dönüştürme\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Sonuçları gösterme\n",
        "print(\"\\nTüm Modellerin Performansı:\")\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juKgCUYj3ZxE",
        "outputId": "7a0baf26-621b-47c3-9869-e1652b077ae2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression\n",
            "Accuracy: 65.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.38      0.46         8\n",
            "           1       0.67      0.83      0.74        12\n",
            "\n",
            "    accuracy                           0.65        20\n",
            "   macro avg       0.63      0.60      0.60        20\n",
            "weighted avg       0.64      0.65      0.63        20\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 60.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.25      0.33         8\n",
            "           1       0.62      0.83      0.71        12\n",
            "\n",
            "    accuracy                           0.60        20\n",
            "   macro avg       0.56      0.54      0.52        20\n",
            "weighted avg       0.57      0.60      0.56        20\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Accuracy: 65.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.25      0.36         8\n",
            "           1       0.65      0.92      0.76        12\n",
            "\n",
            "    accuracy                           0.65        20\n",
            "   macro avg       0.66      0.58      0.56        20\n",
            "weighted avg       0.65      0.65      0.60        20\n",
            "\n",
            "Model: K-Nearest Neighbors\n",
            "Accuracy: 65.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.38      0.46         8\n",
            "           1       0.67      0.83      0.74        12\n",
            "\n",
            "    accuracy                           0.65        20\n",
            "   macro avg       0.63      0.60      0.60        20\n",
            "weighted avg       0.64      0.65      0.63        20\n",
            "\n",
            "Model: Naive Bayes\n",
            "Accuracy: 65.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.25      0.36         8\n",
            "           1       0.65      0.92      0.76        12\n",
            "\n",
            "    accuracy                           0.65        20\n",
            "   macro avg       0.66      0.58      0.56        20\n",
            "weighted avg       0.65      0.65      0.60        20\n",
            "\n",
            "Model: Decision Tree\n",
            "Accuracy: 55.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.50      0.47         8\n",
            "           1       0.64      0.58      0.61        12\n",
            "\n",
            "    accuracy                           0.55        20\n",
            "   macro avg       0.54      0.54      0.54        20\n",
            "weighted avg       0.56      0.55      0.55        20\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Accuracy: 65.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.50      0.53         8\n",
            "           1       0.69      0.75      0.72        12\n",
            "\n",
            "    accuracy                           0.65        20\n",
            "   macro avg       0.63      0.62      0.63        20\n",
            "weighted avg       0.64      0.65      0.65        20\n",
            "\n",
            "\n",
            "Tüm Modellerin Performansı:\n",
            "                    Model  Accuracy\n",
            "0     Logistic Regression      0.65\n",
            "1           Random Forest      0.60\n",
            "2  Support Vector Machine      0.65\n",
            "3     K-Nearest Neighbors      0.65\n",
            "4             Naive Bayes      0.65\n",
            "5           Decision Tree      0.55\n",
            "6       Gradient Boosting      0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Veri kümesi için örnek genetik veriler ve sınıflar oluşturuluyor\n",
        "def random_genetic_data(length):\n",
        "    \"\"\" Rastgele genetik veri üretir. Uzunluk parametresi ile belirlenir. \"\"\"\n",
        "    return ''.join(random.choices(['A', 'T', 'G', 'C'], k=length))\n",
        "\n",
        "# 100 örnek veri oluşturuyoruz\n",
        "data = {\n",
        "    'ID': [i for i in range(1, 101)],\n",
        "    'Genetic_Data': [random_genetic_data(random.randint(5, 15)) for _ in range(100)],  # 5 ile 15 arasında rastgele uzunluk\n",
        "    'Class': [random.choice([0, 1]) for _ in range(100)]  # 0: Hastalıksız, 1: Hastalık Riski\n",
        "}\n",
        "\n",
        "# Veri çerçevesine dönüştürme\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Dosya olarak kaydetme\n",
        "file_path = 'variable_length_genetik_veri.csv'\n",
        "df.to_csv(file_path, index=False)\n",
        "\n",
        "# Dosya yolunu yazdırma\n",
        "print(f\"Veri kümesi '{file_path}' olarak kaydedildi.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_Oy5TKT_Z9c",
        "outputId": "24cf9335-7357-4806-de31-be50405586a6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Veri kümesi 'variable_length_genetik_veri.csv' olarak kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "file_path = 'variable_length_genetik_veri.csv'\n",
        "\n",
        "# 1. Veri Kümesini Yükleme\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 2. Veri Ön İşleme\n",
        "# Genetik veri dizilimlerini sayısal verilere dönüştürmek için CountVectorizer kullanacağız\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 1))  # Karakter bazlı n-gram\n",
        "X = vectorizer.fit_transform(df['Genetic_Data'])  # Genetik veriyi dönüştürüyoruz\n",
        "y = df['Class']  # Sınıf etiketleri\n",
        "\n",
        "# 3. Veriyi Eğitim ve Test Setlerine Ayırma\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Seyrek veriyi yoğun formata dönüştürme (Naive Bayes için)\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "# 4. Farklı Makine Öğrenmesi Modellerini Eğitme ve Performans Analizi\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Support Vector Machine': SVC(),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "# Sonuçları saklamak için bir liste\n",
        "results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    # Modeli eğitme\n",
        "    if model_name == 'Naive Bayes':\n",
        "        model.fit(X_train_dense, y_train)  # Yoğun veri kullan\n",
        "    else:\n",
        "        model.fit(X_train, y_train)  # Seyrek veri kullan\n",
        "\n",
        "    # Test setinde tahmin yapma\n",
        "    y_pred = model.predict(X_test_dense if model_name == 'Naive Bayes' else X_test)\n",
        "\n",
        "    # Doğruluk hesaplama\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Sonuçları listeye ekleme\n",
        "    results.append({'Model': model_name, 'Accuracy': accuracy})\n",
        "\n",
        "    # Model performansını yazdırma\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Sonuçları DataFrame'e dönüştürme\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Sonuçları gösterme\n",
        "print(\"\\nTüm Modellerin Performansı:\")\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDRgR_ZZ_iNu",
        "outputId": "17684906-7e2e-449d-9e0c-fb650f65d693"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression\n",
            "Accuracy: 40.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.17      0.25        12\n",
            "           1       0.38      0.75      0.50         8\n",
            "\n",
            "    accuracy                           0.40        20\n",
            "   macro avg       0.44      0.46      0.38        20\n",
            "weighted avg       0.45      0.40      0.35        20\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 65.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.42      0.59        12\n",
            "           1       0.53      1.00      0.70         8\n",
            "\n",
            "    accuracy                           0.65        20\n",
            "   macro avg       0.77      0.71      0.64        20\n",
            "weighted avg       0.81      0.65      0.63        20\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Accuracy: 50.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.17      0.29        12\n",
            "           1       0.44      1.00      0.62         8\n",
            "\n",
            "    accuracy                           0.50        20\n",
            "   macro avg       0.72      0.58      0.45        20\n",
            "weighted avg       0.78      0.50      0.42        20\n",
            "\n",
            "Model: K-Nearest Neighbors\n",
            "Accuracy: 60.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.33      0.50        12\n",
            "           1       0.50      1.00      0.67         8\n",
            "\n",
            "    accuracy                           0.60        20\n",
            "   macro avg       0.75      0.67      0.58        20\n",
            "weighted avg       0.80      0.60      0.57        20\n",
            "\n",
            "Model: Naive Bayes\n",
            "Accuracy: 45.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.17      0.27        12\n",
            "           1       0.41      0.88      0.56         8\n",
            "\n",
            "    accuracy                           0.45        20\n",
            "   macro avg       0.54      0.52      0.41        20\n",
            "weighted avg       0.56      0.45      0.38        20\n",
            "\n",
            "Model: Decision Tree\n",
            "Accuracy: 55.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.67      0.64        12\n",
            "           1       0.43      0.38      0.40         8\n",
            "\n",
            "    accuracy                           0.55        20\n",
            "   macro avg       0.52      0.52      0.52        20\n",
            "weighted avg       0.54      0.55      0.54        20\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Accuracy: 55.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.42      0.53        12\n",
            "           1       0.46      0.75      0.57         8\n",
            "\n",
            "    accuracy                           0.55        20\n",
            "   macro avg       0.59      0.58      0.55        20\n",
            "weighted avg       0.61      0.55      0.54        20\n",
            "\n",
            "\n",
            "Tüm Modellerin Performansı:\n",
            "                    Model  Accuracy\n",
            "0     Logistic Regression      0.40\n",
            "1           Random Forest      0.65\n",
            "2  Support Vector Machine      0.50\n",
            "3     K-Nearest Neighbors      0.60\n",
            "4             Naive Bayes      0.45\n",
            "5           Decision Tree      0.55\n",
            "6       Gradient Boosting      0.55\n"
          ]
        }
      ]
    }
  ]
}